# Configuração
## Fonte: [Build a Simple LLM Application](https://python.langchain.com/docs/tutorials/llm_chain/)
Para executar este exemplo, você precisa criar um ambiente virtual Python e instalar as dependências.

```
python3.10 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Depois, atualize o arquivo retirando os comentários para a criação da variável _llm_ de acordo com a máquina que está executando o Ollama.

Por último:

```
python SimpleLLM.py
```

