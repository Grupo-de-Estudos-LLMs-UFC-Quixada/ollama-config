# Configuração

Para executar este exemplo, você precisa criar um ambiente virtual Python e instalar as dependências.

```
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Depois, atualize o arquivo retirando os comentários para a criação da variável _llm_ de acordo com a máquina que está executando o Ollama.

Por último:

```
python SimpleLLM.py
```

