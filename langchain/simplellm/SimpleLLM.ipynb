{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94f5e22-da58-486f-ae80-e8e059858b2e",
   "metadata": {},
   "source": [
    "# Instalar o LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0421de-82f3-4b07-a98a-38258c867fbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.16)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.1.142)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.13/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de25971-a7a3-41f7-a6bd-05a6b5d6dfc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Instalar Integração com o Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5cefc9b-2f61-4b0c-af5e-9dba3e2f48ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30441da-15c3-4561-b209-161b4f889e3c",
   "metadata": {},
   "source": [
    "# Criar Conexão com o Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e7b250-1c4c-470d-91f1-83bd8dd01509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf8819-b143-4630-8bb8-07ac8fc24715",
   "metadata": {},
   "source": [
    "# Fazer uma Requisição de Tradução "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f7bea-4af0-4482-abc1-90a707b24eec",
   "metadata": {},
   "source": [
    "Aqui, _SystemMessage_ parece ser instruções para o modelo, enquanto _HumanMessage_ seria o conteúdo de fato fornecido pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd85d9da-7d3b-47c0-910c-1dc137ac4356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Eu amo programar.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-11-12T20:02:39.982311Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 206631833, 'load_duration': 32054875, 'prompt_eval_count': 58, 'prompt_eval_duration': 74000000, 'eval_count': 6, 'eval_duration': 99000000}, id='run-3d4afc51-8fa2-40f5-a554-39867d68235f-0', usage_metadata={'input_tokens': 58, 'output_tokens': 6, 'total_tokens': 64})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Você é um assistente útil que traduz do Inglês para o Português. Traduza a sequência a seguir.\"),\n",
    "    HumanMessage(content=\"I love programming.\"),\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc682677-c77d-4263-b448-6406fe345dcb",
   "metadata": {},
   "source": [
    "# Processando a Saída"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e594ddd-e067-4f98-b1b6-095f7945e0c9",
   "metadata": {},
   "source": [
    "A saída anterior tem várias informações além da tradução. Vamos criar um _parser_ para extrair a resposta e ignorar os metadados do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cbf0caf-e7d6-47d6-8fd4-e2dad4fe692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090f810-b3d7-476f-bb9f-eb70cc4807e7",
   "metadata": {},
   "source": [
    "Vamos fazer uma ligação (_chain_) entre o modelo (_llm_) e o _parser_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e424d8f-47d0-46b4-9f3a-f01814b5b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfda7ae-1db3-4db7-a9c4-98c07ea36b3d",
   "metadata": {},
   "source": [
    "Por último, invocamos a ligação com a mensagem a ser tratada pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f80f29a-7346-4236-8c8e-0e9395dfa773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eu amo programar.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550f6de-c596-4b0f-b64b-f1d9be20c42d",
   "metadata": {},
   "source": [
    "# Modelos de _Prompt_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59df4ea-bdca-4eaf-ae0e-00705039fe20",
   "metadata": {},
   "source": [
    "Modelos de _prompt_ permitem preparar a entrada de acordo com um formato que aumente a chance de receber a resposta desejada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c0501e-2b56-4a48-adcf-7637afd74e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89848ac-d63f-45af-8d6a-5d23d2eac5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a translator that only outputs the translation requested. Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ab4b4fd-0fba-471c-a102-b144db4aa598",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2153d-7f7d-4a11-abde-14a6108678d4",
   "metadata": {},
   "source": [
    "Aqui o _invoke_ só apresenta como o modelo está construindo, ainda não passa o _prompt_ ao modelo LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b64366b2-ab28-4192-86e1-99159b5fe388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You a translator that only outputs the translation requested. Translate the following into italian:', additional_kwargs={}, response_metadata={}), HumanMessage(content='car', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"car\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc9dd592-0c22-4730-b8ca-1202c0191c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You a translator that only outputs the translation requested. Translate the following into italian:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='car', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaddd5-1026-4124-badb-25fa9e822f0b",
   "metadata": {},
   "source": [
    "Vamos criar a ligação entre o _prompt_, o modelo LLM e o _parser_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfb5e0aa-24d4-440f-94ce-0d076463ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4d05df4-08d4-40de-992c-ae286bc289bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automobile'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italiano\", \"text\": \"car\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
